import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import datetime
import os
from collections import Counter
import glob

pd.set_option('display.max_columns', None)
np.random.seed(4)
### Load the data
data = pd.read_csv("Data/transactions_train.csv", dtype={'article_id':str})

data.head()
articles = pd.read_csv("Data/articles.csv", dtype={'article_id':str})

customers = pd.read_csv("Data/customers.csv", dtype={'customer_id':str})
customers.shape
print("All Transactions Date Range: {} to {}".format(data['t_dat'].min(), data['t_dat'].max()))

data["t_dat"] = pd.to_datetime(data["t_dat"])

train = data.loc[(data["t_dat"] >= datetime.datetime(2020,8,24)) & (data['t_dat'] < datetime.datetime(2020,9,16))]

val = data.loc[data["t_dat"] >= datetime.datetime(2020,9,16)]
train.head()
val.head()
# List of all purchases per user (has repetitions)

positive_items_per_user = train.groupby(['customer_id'])['article_id'].apply(list)

train['pop_factor'] = train['t_dat'].apply(lambda x: 1/(datetime.datetime(2020,9,16) - x).days)

popular_items_group = train.groupby(['article_id'])['pop_factor'].sum()

_, popular_items = zip(*sorted(zip(popular_items_group, popular_items_group.keys()))[::-1])

train['pop_factor'].describe()
def apk(actual, predicted, k=12):
    '''
    Computes the average precision at k.
    '''
    if len(predicted)>k:
        predicted = predicted[:k]

    score = 0.0
    num_hits = 0.0

    for i,p in enumerate(predicted):
        if p in actual and p not in predicted[:i]:
            num_hits += 1.0
            score += num_hits / (i+1.0)

    if not actual:
        return 0.0

    return score / min(len(actual), k)

def mapk(actual, predicted, k=12):
    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])
positive_items_val = val.groupby(['customer_id'])['article_id'].apply(list)

# creating validation set for metrics use case

val_users = positive_items_val.keys()
val_items = []

for i,user in tqdm(enumerate(val_users)):
    val_items.append(positive_items_val[user])
    
print("Total users in validation:", len(val_users))
pd.DataFrame(positive_items_val)['article_id'].apply(len).value_counts().plot(kind='bar')
outputs = []
cnt = 0

popular_items = list(popular_items)

for user in tqdm(val_users):
    user_output = []
    if user in positive_items_per_user.keys():
        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user[user]).most_common()}
        user_output += list(most_common_items_of_user.keys())
    
    user_output += list(popular_items[:12 - len(user_output)])
    outputs.append(user_output)
    
print("mAP Score on Validation set:", mapk(val_items, outputs))

# Load image paths and create image_ids dataframe
images = glob.glob("Data/images/*/*", recursive=True)
image_ids = pd.DataFrame([{'image_id': image.split('/')[-1].split('.')[0], 'path': image} for image in images])

# Import visualize_bought function
from Utils.utils import visualize_bought

# Visualize bought items for the first user in the training set
first_user_id = train['customer_id'].iloc[0]
visualize_bought(first_user_id, train, image_ids)
